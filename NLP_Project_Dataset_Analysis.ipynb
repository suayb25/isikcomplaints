{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Project_Dataset_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9Lt36inA8bu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fc63ace-a140-49e6-f232-1a10f7b36feb"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "df = pd.read_excel('dataset.xlsx')\n",
        "df.info()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48 entries, 0 to 47\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   id       48 non-null     int64  \n",
            " 1   text     48 non-null     object \n",
            " 2   subject  0 non-null      float64\n",
            "dtypes: float64(1), int64(1), object(1)\n",
            "memory usage: 1.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "OXkcLvhW_YIE",
        "outputId": "74386750-12e1-4645-d77f-9ca32c1a5f6a"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Açılış törenlerinde binlerce kişiyi bir araya ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Okulun sitesinde paylaşılmış. Fiyatlar şaka gi...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>merhaba, 2. sınıfların kayıt günü bugün olduğu...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Bu nasıl bir rezilliktir ya sabah saat 9 dan b...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Dalga geçer gibi mat102 dersini ilk kez bu dön...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                               text  subject\n",
              "0   0  Açılış törenlerinde binlerce kişiyi bir araya ...      NaN\n",
              "1   1  Okulun sitesinde paylaşılmış. Fiyatlar şaka gi...      NaN\n",
              "2   2  merhaba, 2. sınıfların kayıt günü bugün olduğu...      NaN\n",
              "3   3  Bu nasıl bir rezilliktir ya sabah saat 9 dan b...      NaN\n",
              "4   4  Dalga geçer gibi mat102 dersini ilk kez bu dön...      NaN"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO9HPXwcgIw5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7e340f98-03c8-4bad-e732-066698814b2c"
      },
      "source": [
        "df['text'][5]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Ders programı hala açıklanmadı. Son sınıfım bir sürü seçmeli dersim var hangisini alacağımı bilmiyorum ve yarın ders seçimi var. Okulu arıyorum yardımcı olan yok. Şaşırtmadın yine Işık Üniversitesi.'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9gRZoRYPfW4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01f4a184-78e9-424c-ebfe-6fe66d4f9b11"
      },
      "source": [
        "from collections import Counter\n",
        "Counter(\" \".join(df[\"text\"]).split()).most_common(100)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bir', 59),\n",
              " ('bu', 53),\n",
              " ('ve', 42),\n",
              " ('ne', 21),\n",
              " ('de', 21),\n",
              " ('için', 20),\n",
              " ('kadar', 18),\n",
              " ('da', 18),\n",
              " ('çok', 17),\n",
              " ('gibi', 13),\n",
              " ('ben', 13),\n",
              " ('ama', 13),\n",
              " ('şey', 13),\n",
              " ('1', 12),\n",
              " ('var', 12),\n",
              " ('bi', 12),\n",
              " ('o', 12),\n",
              " ('mi', 12),\n",
              " ('en', 12),\n",
              " ('her', 12),\n",
              " ('bile', 11),\n",
              " ('Bu', 11),\n",
              " ('daha', 11),\n",
              " ('okul', 11),\n",
              " ('sadece', 10),\n",
              " ('ders', 10),\n",
              " ('başka', 10),\n",
              " ('ki', 10),\n",
              " ('yok', 10),\n",
              " ('öğrenci', 9),\n",
              " ('okulun', 9),\n",
              " ('olan', 9),\n",
              " ('online', 9),\n",
              " ('ile', 9),\n",
              " ('fakat', 8),\n",
              " ('mı', 8),\n",
              " ('gerçekten', 8),\n",
              " ('nasıl', 7),\n",
              " ('ya', 7),\n",
              " ('dönem', 7),\n",
              " ('olarak', 7),\n",
              " ('artık', 7),\n",
              " ('bize', 7),\n",
              " ('lütfen', 6),\n",
              " ('yine', 6),\n",
              " ('kota', 6),\n",
              " ('Bir', 6),\n",
              " ('2', 6),\n",
              " ('şu', 6),\n",
              " ('olduğu', 5),\n",
              " ('mail', 5),\n",
              " ('neden', 5),\n",
              " ('acaba', 5),\n",
              " ('için.', 5),\n",
              " ('düzgün', 5),\n",
              " ('diyelim', 5),\n",
              " ('proje', 5),\n",
              " ('arkadaşlar', 5),\n",
              " ('Işık', 5),\n",
              " ('öyle', 5),\n",
              " ('değil.', 5),\n",
              " ('zaten', 5),\n",
              " ('aynı', 5),\n",
              " ('respondus', 5),\n",
              " ('bazı', 5),\n",
              " ('yurt', 5),\n",
              " ('yani', 5),\n",
              " ('insanlar', 5),\n",
              " ('hiçbir', 5),\n",
              " ('bütün', 5),\n",
              " ('kamera', 5),\n",
              " ('eğitim', 4),\n",
              " ('ışık', 4),\n",
              " ('üniversitesi', 4),\n",
              " ('ses', 4),\n",
              " ('kayıt', 4),\n",
              " ('dersim', 4),\n",
              " ('danışmanıma', 4),\n",
              " ('diyor', 4),\n",
              " ('işlerine', 4),\n",
              " ('onlar', 4),\n",
              " ('para', 4),\n",
              " ('hadi', 4),\n",
              " ('yarın', 4),\n",
              " ('dersine', 4),\n",
              " ('mezun', 4),\n",
              " ('ilk', 4),\n",
              " ('hala', 4),\n",
              " ('derslerim', 4),\n",
              " ('dersleri', 4),\n",
              " ('benim', 4),\n",
              " ('?', 4),\n",
              " ('hiç', 4),\n",
              " ('şekilde', 4),\n",
              " ('kim', 4),\n",
              " ('okula', 4),\n",
              " ('Merhaba', 4),\n",
              " ('dakika', 4),\n",
              " ('olup', 4),\n",
              " ('okulda', 4)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwzYhWuEQR_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b870a772-98e1-403c-81de-ced4f6631e08"
      },
      "source": [
        "set(df.text.apply(list).sum())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ',\n",
              " '!',\n",
              " '\"',\n",
              " '%',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'Y',\n",
              " 'Z',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'y',\n",
              " 'z',\n",
              " 'Ç',\n",
              " 'Ö',\n",
              " 'Ü',\n",
              " 'ç',\n",
              " 'ö',\n",
              " 'ü',\n",
              " 'ğ',\n",
              " 'İ',\n",
              " 'ı',\n",
              " 'Ş',\n",
              " 'ş'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEMrQAClWftf"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing import sequence"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH-JrzxYSBlv"
      },
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(df['text'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YdKb4E4XRRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8124a665-5901-441f-b7a5-238a6017be0e"
      },
      "source": [
        "print(len(df['text']))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewSj46MzW8Qr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdc63989-dffd-475b-efcd-d7f91fcf1b78"
      },
      "source": [
        "tokenizer.texts_to_sequences([\"Ders\"])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[11, 3, 5, 13]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR4yQUbdVouV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51ce53a6-44bf-424e-9bbd-55662ac3e663"
      },
      "source": [
        "tokenizer.sequences_to_texts([[11, 3, 5, 13]])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['d e r s']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGC_xOyj6_ct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35fe7b04-9cda-4c4e-98b4-ec74c36f2992"
      },
      "source": [
        "tokenizer.sequences_to_texts([[13, 14 ,2 ,12 ,17]]) "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['s u a y b']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyOrf7EAXCUY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d030069c-5f6a-45ef-c73c-23b40078ddb9"
      },
      "source": [
        "max_id = len(tokenizer.word_index) # number of distinct characters\n",
        "dataset_size = tokenizer.document_count # total number of characters\n",
        "print(max_id)\n",
        "print(dataset_size)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55\n",
            "48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbaTuMW8WD6W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "37f42e2c-34a8-4185-dcb2-45ecb22a09ec"
      },
      "source": [
        "df['text'][0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Açılış törenlerinde binlerce kişiyi bir araya toplayan, İşletme ekonominin düzenlediği etkinlikte maskesiz, mesafesiz eğlence, etkinlik ve eğitimler düzenleyen ve bunu açıkça paylaşan fakat 40 kişilik sınıfları bile virüsü bahane ederek uzaktan eğitim almaya mecbur kılan bir ışık üniversitesi bırakıyorum buraya'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws2OBEXFXHr8"
      },
      "source": [
        "[encoded] = np.array(tokenizer.texts_to_sequences([\" \".join(df[\"text\"]).split()])) - 1\n",
        "train_size = dataset_size * 90 // 100\n",
        "#dataset = tf.data.Dataset.from_tensor_slices(df['text'])\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcdmIwneS0F2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c5e4a34-cd43-4d90-c978-a05ef5737b8e"
      },
      "source": [
        "print(encoded.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(43,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvxYVLs3YNKS"
      },
      "source": [
        "n_steps = 100\n",
        "window_length = n_steps + 1 # target = input shifted 1 character ahead\n",
        "dataset = dataset.repeat().window(window_length, shift=1, drop_remainder=True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBpbXKBbYQ9B"
      },
      "source": [
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXjmXiwyYTqP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08f8d47e-ecd3-4e26-e59b-1831244012d5"
      },
      "source": [
        "for a in dataset.take(5):\n",
        "  print(a)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[32 14 43 14  1 31 14 14 14 32 14 32 32 32 14 32 14  2 23 31 34 32 34 31\n",
            " 41 32 32 14 34 34 39 32 48 31 34 34 32 32 14 14 14 39 48 32 14 43 14  1\n",
            " 31 14 14 14 32 14 32 32 32 14 32 14  2 23 31 34 32 34 31 41 32 32 14 34\n",
            " 34 39 32 48 31 34 34 32 32 14 14 14 39 48 32 14 43 14  1 31 14 14 14 32\n",
            " 14 32 32 32 14], shape=(101,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[14 43 14  1 31 14 14 14 32 14 32 32 32 14 32 14  2 23 31 34 32 34 31 41\n",
            " 32 32 14 34 34 39 32 48 31 34 34 32 32 14 14 14 39 48 32 14 43 14  1 31\n",
            " 14 14 14 32 14 32 32 32 14 32 14  2 23 31 34 32 34 31 41 32 32 14 34 34\n",
            " 39 32 48 31 34 34 32 32 14 14 14 39 48 32 14 43 14  1 31 14 14 14 32 14\n",
            " 32 32 32 14 32], shape=(101,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[43 14  1 31 14 14 14 32 14 32 32 32 14 32 14  2 23 31 34 32 34 31 41 32\n",
            " 32 14 34 34 39 32 48 31 34 34 32 32 14 14 14 39 48 32 14 43 14  1 31 14\n",
            " 14 14 32 14 32 32 32 14 32 14  2 23 31 34 32 34 31 41 32 32 14 34 34 39\n",
            " 32 48 31 34 34 32 32 14 14 14 39 48 32 14 43 14  1 31 14 14 14 32 14 32\n",
            " 32 32 14 32 14], shape=(101,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[14  1 31 14 14 14 32 14 32 32 32 14 32 14  2 23 31 34 32 34 31 41 32 32\n",
            " 14 34 34 39 32 48 31 34 34 32 32 14 14 14 39 48 32 14 43 14  1 31 14 14\n",
            " 14 32 14 32 32 32 14 32 14  2 23 31 34 32 34 31 41 32 32 14 34 34 39 32\n",
            " 48 31 34 34 32 32 14 14 14 39 48 32 14 43 14  1 31 14 14 14 32 14 32 32\n",
            " 32 14 32 14  2], shape=(101,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[ 1 31 14 14 14 32 14 32 32 32 14 32 14  2 23 31 34 32 34 31 41 32 32 14\n",
            " 34 34 39 32 48 31 34 34 32 32 14 14 14 39 48 32 14 43 14  1 31 14 14 14\n",
            " 32 14 32 32 32 14 32 14  2 23 31 34 32 34 31 41 32 32 14 34 34 39 32 48\n",
            " 31 34 34 32 32 14 14 14 39 48 32 14 43 14  1 31 14 14 14 32 14 32 32 32\n",
            " 14 32 14  2 23], shape=(101,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwTiCrugYhOc"
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRHbqw09YkSM"
      },
      "source": [
        "batch_size = 32\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0fq981OYmoV"
      },
      "source": [
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_JdPx-EYor1"
      },
      "source": [
        "dataset = dataset.prefetch(1)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iytg4iV-Yqvy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7760c72-1b39-4f49-9065-c91cf64a73cd"
      },
      "source": [
        "for X_batch, Y_batch in dataset.take(1):\n",
        "    print(X_batch.shape, Y_batch.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 100, 55) (32, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up0aJ3leYtWm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8a61a0d-b1e2-4dde-c9de-5a0c29559c6c"
      },
      "source": [
        "print(tf.argmax(X_batch[0,0:10,:],axis=1))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([32 14 43 14  1 31 14 14 14 32], shape=(10,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osR0n1G3YwcK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90f37f3a-36cb-47c4-b0eb-8cc4cfd5c868"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(8, return_sequences=True, input_shape=[None, max_id]\n",
        "                     # no dropout in stateful RNN (https://github.com/ageron/handson-ml2/issues/32)\n",
        "                     # dropout=0.2, recurrent_dropout=0.2,\n",
        "                     ),\n",
        "    keras.layers.GRU(8, return_sequences=True\n",
        "                     # dropout=0.2, recurrent_dropout=0.2\n",
        "                    ),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                    activation=\"softmax\"))\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "history = model.fit(dataset, steps_per_epoch=train_size // batch_size,\n",
        "                    epochs=5)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 11s 11s/step - loss: 3.9920\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.9880\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.9843\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.9804\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.9762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ffnwhXXBUZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "710a34b4-e32e-4199-facc-36de40e106a0"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru (GRU)                   (None, None, 8)           1560      \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, None, 8)           432       \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, None, 55)         495       \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,487\n",
            "Trainable params: 2,487\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dxY84-Ub2vP"
      },
      "source": [
        "def preprocess(texts):\n",
        "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
        "    return tf.one_hot(X, max_id)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j012G8aRb5tc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e0821389-d76f-4abc-a4a0-b7da85acad23"
      },
      "source": [
        "X_new = preprocess([\"Ders\"])\n",
        "Y_pred = model.predict(X_new)\n",
        "classes_x=np.argmax(Y_pred,axis=1)\n",
        "tokenizer.sequences_to_texts(classes_x + 1)[0][-1] # 1st sentence, last char"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i'"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKPNiPkAc35p"
      },
      "source": [
        "def next_char(text, temperature=1):\n",
        "    X_new = preprocess([text])\n",
        "    y_proba = model.predict(X_new)[0, -1:, :]\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1 #argmax\n",
        "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbrdm0dbcsiG"
      },
      "source": [
        "def complete_text(text, n_chars=50, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6rd3pj3cwJS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dbb5924-38c7-4fa1-de73-a5f140704e6c"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "print(complete_text(\"Ders\", temperature=1))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ders%;0f;ds(nsk.ö'tia3̇%17'yv1zm?:2-ğ ;.h2!if 9it)e4̇d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo7gmeoUYQP4"
      },
      "source": [
        "**Comments :**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58evn7EZW5jz"
      },
      "source": [
        "1) If we want better complete text results we need to use Turkish tokenizer. Results are not so good because the system is for English words.\n",
        "\n",
        "2) In this dataset, sentences are not so good, I mean sentences structure is \n",
        "broken so model is not training so good.\n",
        "\n",
        "3) Other thing is dataset is small. If we use a dataset which includes 2000 sentences text, results can be better than this.\n",
        "\n",
        "For Example: Turkish Pre-trained Word2Vec Model, Zemberek\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t5YUrLW_OqB"
      },
      "source": [
        "Another trying"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prD00WD3m-Ya"
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLqGTAsRsWwT"
      },
      "source": [
        "X=df['text'].values.tolist()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QzHjPJRrQm5"
      },
      "source": [
        "num_words = 50\n",
        "tokenizer = Tokenizer(num_words = num_words)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyMrCcjhrUC2"
      },
      "source": [
        "tokenizer.fit_on_texts(X)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wUulFQcrlCo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56b5dc47-a515-4e53-d701-2acdc3c6d6e6"
      },
      "source": [
        "counter = 0\n",
        "for word in tokenizer.word_index:\n",
        "    counter = counter + 1\n",
        "    print(counter, \"-> \", word)\n",
        "    if(counter == 20):\n",
        "        break"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 ->  bu\n",
            "2 ->  bir\n",
            "3 ->  ve\n",
            "4 ->  için\n",
            "5 ->  ne\n",
            "6 ->  de\n",
            "7 ->  kadar\n",
            "8 ->  var\n",
            "9 ->  da\n",
            "10 ->  1\n",
            "11 ->  çok\n",
            "12 ->  okul\n",
            "13 ->  ben\n",
            "14 ->  her\n",
            "15 ->  gibi\n",
            "16 ->  mi\n",
            "17 ->  ama\n",
            "18 ->  şey\n",
            "19 ->  bile\n",
            "20 ->  bi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1-8PEq5sw4e"
      },
      "source": [
        "X_train_tokens = tokenizer.texts_to_sequences(X)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUVfSHAMs262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fc2ad742-e57b-45fb-9d20-8226fbc727e0"
      },
      "source": [
        "X[20]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Ağustos'ta ödeyip ödeme dekontunu mail atıp teyidini aldığım yurt borcumu sistemden silmedikleri ve 2 gündür ne bir mailime ne de bir telefonuma cevap vermedikleri için ders seçemedim. Teşekkürler ışık üniversitesi, harika bir üniversite deneyimi yaşatıyorsun gerçekten.\""
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJlsGzpBs7YM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "248ee67f-4324-4704-9f2b-4021776062b2"
      },
      "source": [
        "np.array(X_train_tokens[20])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3, 36,  5,  2,  5,  6,  2,  4, 28, 47,  2, 21])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j1qIKUhtteS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f36ca96-4b6b-431f-a325-161d537bad61"
      },
      "source": [
        "num_tokens = [len(tokens) for tokens in X_train_tokens]\n",
        "num_tokens = np.array(num_tokens)\n",
        "num_tokens"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7, 17, 29, 11, 15,  9, 16,  2, 28,  3, 13, 13,  9, 29,  9, 12, 34,\n",
              "        6, 16,  3, 12,  4, 22, 15, 26,  8,  8,  9, 13, 17,  8, 11, 11,  3,\n",
              "       19, 15,  4, 12, 44, 19, 30, 13, 22, 29, 17, 17, 20, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcVot7Xutzz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33abf831-738c-415c-a279-f7a6183c5ec1"
      },
      "source": [
        "import math\n",
        "max_tokens = np.mean(num_tokens) + 2*np.std(num_tokens)\n",
        "max_tokens = math.ceil(max_tokens)\n",
        "max_tokens"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzQ3LzvGtE7l"
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "X_train_pad = pad_sequences(X_train_tokens, maxlen = max_tokens)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMgfgN2Xt7Lt"
      },
      "source": [
        "idx = tokenizer.word_index\n",
        "inverse_map = dict(zip(idx.values(), idx.keys()))"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpyWvFbut-XF"
      },
      "source": [
        "def tokens_to_string(tokens):\n",
        "    words = (inverse_map[token] for token in tokens if token != 0)\n",
        "    text = \" \".join(words)\n",
        "    return text"
      ],
      "execution_count": 69,
      "outputs": []
    }
  ]
}